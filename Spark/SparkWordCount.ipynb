{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark assignment 1: Pairs\n",
    "Find all the pairs of two consequent words where the first word is “narodnaya”. For each pair, count the number of occurrences in the Wikipedia dump. Print all the pairs with their count in a lexicographical order. Output format is “word_pair <tab> count”, for example:\n",
    "\n",
    "red_apple\t100500\n",
    "\n",
    "crazy_zoo\t42\n",
    "\n",
    "Note that two words in a pair are concatenated with the underscore character, and the result is in the lowercase.\n",
    "\n",
    "One motivation for counting these continuations is to get a better understanding of the language. Some words, like “the”, have a lot of continuations, while others, like “San”, have just a few (“San Francisco”, for example). One can build a language model with these statistics. If you are interested to learn more, search for “n-gram language model” in the Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext(conf=SparkConf().setAppName(\"MyApp\").setMaster(\"local\"))\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_article(line):\n",
    "    try:\n",
    "        article_id, text = unicode(line.rstrip()).lower().split('\\t', 1)\n",
    "        text = re.sub(\"^\\W+|\\W+$\", \"\", text, flags=re.UNICODE)\n",
    "        words = re.split(\"\\W*\\s+\\W*\", text, flags=re.UNICODE)\n",
    "        return words\n",
    "    except ValueError as e:\n",
    "        return []\n",
    "    \n",
    "wiki = sc.textFile(\"/data/wiki/en_articles_part/articles-part\", 16).map(parse_article) #one to one map\n",
    "result = wiki.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anarchism\n",
      "anarchism\n",
      "is\n",
      "often\n",
      "defined\n",
      "as\n",
      "a\n",
      "political\n",
      "philosophy\n",
      "which\n",
      "holds\n",
      "the\n",
      "state\n",
      "to\n",
      "be\n",
      "undesirable\n",
      "unnecessary\n",
      "or\n",
      "harmful\n",
      "the\n",
      "following\n",
      "sources\n",
      "cite\n",
      "anarchism\n",
      "as\n",
      "a\n",
      "political\n",
      "philosophy\n",
      "slevin\n",
      "carl\n",
      "anarchism\n",
      "the\n",
      "concise\n",
      "oxford\n",
      "dictionary\n",
      "of\n",
      "politics\n",
      "ed\n",
      "iain\n",
      "mclean\n",
      "and\n",
      "alistair\n",
      "mcmillan\n",
      "oxford\n",
      "university\n",
      "press\n",
      "2003\n",
      "however\n",
      "others\n",
      "argue\n"
     ]
    }
   ],
   "source": [
    "for word in result[:50]:\n",
    "    print word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_words(words, key_word=\"narodnaya\"):\n",
    "    word_list=[]\n",
    "    for inx, word in enumerate(words[:-1]):\n",
    "        if word==key_word:\n",
    "            word_list.append((word+\"_\"+words[inx+1],1))        \n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'narodnaya_volya', 1),\n",
       " (u'narodnaya_volya', 1),\n",
       " (u'narodnaya_volya', 1),\n",
       " (u'narodnaya_volya', 1),\n",
       " (u'narodnaya_volya', 1),\n",
       " (u'narodnaya_volya', 1),\n",
       " (u'narodnaya_volya', 1),\n",
       " (u'narodnaya_volya', 1),\n",
       " (u'narodnaya_volya', 1),\n",
       " (u'narodnaya_gazeta', 1)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paired_words = wiki.flatMap(lambda x : pair_words(x)) #flat map is * to many transformation which transform each element from 0 to M\n",
    "#map is one to one, that's why we need to devide map with flat map\n",
    "\n",
    "paired_words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_reduce = paired_words.reduceByKey(lambda x, y : x+y).sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'narodnaya_gazeta', 1), (u'narodnaya_volya', 9)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_reduce.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "narodnaya_gazeta\t1\n",
      "narodnaya_volya\t9\n"
     ]
    }
   ],
   "source": [
    "result = word_reduce.collect()\n",
    "for key, value in result:\n",
    "    print(\"{0}\\t{1}\".format(key,value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
