{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have precreated database `stackoverflow_`. Firstly, investigate it. What tables does it has?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive Assignment 2. DML: Find Most Popular Tags\n",
    "Compare most popular tags in year 2016 with tags in 2009. Tag popularity is the number of questions (post_type_id=1) with this tag. Output top 10 tags in format:\n",
    "\n",
    "\n",
    "\n",
    "Example:\n",
    "`tag <tab> rank in 2016 <tab> rank in 2009 <tab> tag popularity in 2016 <tab> tag popularity in 2009`\n",
    "\n",
    "`php 5 3 1234 5678`\n",
    "\n",
    "\n",
    "* For 'rank' in each year use rank() function. Order by 'rank in 2016'.\n",
    "\n",
    "\n",
    "\n",
    "* The part of the result on the sample dataset:\n",
    "`...\n",
    "android 3   52  1809    25\n",
    "php 4   3   1673    215\n",
    "python  5   11  1585    108\n",
    "c#  6   1   1519    423\n",
    "...`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "OK\n",
      "Time taken: 0.309 seconds\n",
      "OK\n",
      "posts\n",
      "users\n",
      "Time taken: 0.109 seconds, Fetched: 2 row(s)\n"
     ]
    }
   ],
   "source": [
    "! hive --database stackoverflow_ -e 'show tables'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Querying to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add necessary JAR-files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query.hql\n",
    "\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include precreated database `stackoverflow_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a query.hql\n",
    "\n",
    "USE stackoverflow_;\n",
    "DESCRIBE posts;\n",
    "DESCRIBE users;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, write a simple query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a query.hql\n",
    "\n",
    "SELECT * FROM posts LIMIT 10;\n",
    "SELECT * FROM users LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's execute received `HiveQL`-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar]\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar]\n",
      "OK\n",
      "Time taken: 0.29 seconds\n",
      "OK\n",
      "id                  \tint                 \t                    \n",
      "post_type_id        \ttinyint             \t                    \n",
      "date                \tstring              \t                    \n",
      "owner_user_id       \tint                 \t                    \n",
      "parent_id           \tint                 \t                    \n",
      "score               \tint                 \t                    \n",
      "favorite_count      \tint                 \t                    \n",
      "tags                \tarray<string>       \t                    \n",
      "year                \tstring              \t                    \n",
      "month               \tstring              \t                    \n",
      "\t \t \n",
      "# Partition Information\t \t \n",
      "# col_name            \tdata_type           \tcomment             \n",
      "\t \t \n",
      "year                \tstring              \t                    \n",
      "month               \tstring              \t                    \n",
      "Time taken: 0.296 seconds, Fetched: 16 row(s)\n",
      "OK\n",
      "id                  \tint                 \t                    \n",
      "reputation          \tint                 \t                    \n",
      "creation_date       \tstring              \t                    \n",
      "display_name        \tstring              \t                    \n",
      "location            \tstring              \t                    \n",
      "views               \tint                 \t                    \n",
      "up_votes            \tint                 \t                    \n",
      "down_votes          \tint                 \t                    \n",
      "age                 \tint                 \t                    \n",
      "account_id          \tint                 \t                    \n",
      "Time taken: 0.038 seconds, Fetched: 10 row(s)\n",
      "OK\n",
      "45\t2\t2008-08-01T12:56:37.920\t39\t39\t34\tNULL\tNULL\t2008\t2008-08\n",
      "243\t2\t2008-08-01T22:31:36.137\t71\t234\t12\tNULL\tNULL\t2008\t2008-08\n",
      "304\t2\t2008-08-02T01:38:14.077\t91\t109\t2\tNULL\tNULL\t2008\t2008-08\n",
      "629\t2\t2008-08-03T07:28:54.070\t122\t626\t38\tNULL\tNULL\t2008\t2008-08\n",
      "893\t2\t2008-08-03T23:38:05.113\t234\t871\t6\tNULL\tNULL\t2008\t2008-08\n",
      "1394\t2\t2008-08-04T16:38:03.667\t91\t1390\t16\tNULL\tNULL\t2008\t2008-08\n",
      "1686\t2\t2008-08-04T23:08:18.603\t316\t1669\t43\tNULL\tNULL\t2008\t2008-08\n",
      "2069\t2\t2008-08-05T10:22:55.653\t307\t2056\t23\tNULL\tNULL\t2008\t2008-08\n",
      "2712\t2\t2008-08-05T19:09:08.213\t350\t2639\t10\tNULL\tNULL\t2008\t2008-08\n",
      "2799\t2\t2008-08-05T20:26:08.103\t308\t2767\t34\tNULL\tNULL\t2008\t2008-08\n",
      "Time taken: 0.424 seconds, Fetched: 10 row(s)\n",
      "OK\n",
      "37\t4146\t2008-08-01T12:44:00.723\tWally Lawless\tGeorgetown, Canada\t654\t256\t18\t35\t28\n",
      "169\t4825\t2008-08-02T22:51:03.507\tArnold Zokas\tLondon, United Kingdom\t585\t1956\t14\tNULL\t138\n",
      "194\t15481\t2008-08-03T10:56:49.987\tAdam Haile\tUnited States\t1973\t217\t18\t33\t157\n",
      "338\t37578\t2008-08-04T18:34:44.117\tFrank Krueger\tUnited States\t3941\t2411\t93\t36\t272\n",
      "480\t276\t2008-08-06T08:40:05.797\tmdy\tAsia\t79\t49\t0\t28\t381\n",
      "756\t2358\t2008-08-08T15:31:50.013\tSimon Gillbee\tPearland, TX\t478\t352\t25\t45\t587\n",
      "923\t58\t2008-08-10T14:25:39.540\tAnotherHowie\tUnited Kingdom\t32\t2\t0\t45\t706\n",
      "1097\t8036\t2008-08-12T11:40:09.933\tGeoff\tStow, OH\t527\t473\t30\t46\t838\n",
      "1462\t2011\t2008-08-15T17:26:18.470\tcrono\tGermany\t119\t73\t1\t35\t1101\n",
      "1539\t2476\t2008-08-16T13:31:36.823\tRyan P\tUnited States\t233\t72\t9\t33\t1158\n",
      "Time taken: 0.141 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "! hive -f query.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting query2.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query2.hql\n",
    "USE stackoverflow_;\n",
    "\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar;\n",
    "\n",
    "\n",
    "SELECT c.token, c.rank, p.rank, c.cnt, p.cnt \n",
    "FROM\n",
    "    (SELECT exploded.year as year, exploded.cnt as cnt, exploded.myCol1 as token, RANK() OVER (ORDER BY exploded.cnt DESC) rank \n",
    "    FROM\n",
    "        (SELECT year, myCol1, COUNT(*) AS cnt FROM posts\n",
    "            LATERAL VIEW explode(tags) myTable1 AS myCol1\n",
    "            WHERE post_type_id = 1 AND year = 2016\n",
    "            GROUP BY year, myCol1) as exploded\n",
    "    WHERE exploded.year = 2016\n",
    "    LIMIT 10) AS c\n",
    "LEFT OUTER JOIN \n",
    "    (SELECT exploded.year as year, exploded.cnt as cnt, exploded.myCol1 as token, RANK() OVER (ORDER BY exploded.cnt DESC) rank \n",
    "    FROM\n",
    "        (SELECT year, myCol1, COUNT(*) AS cnt FROM posts\n",
    "            LATERAL VIEW explode(tags) myTable1 AS myCol1\n",
    "            WHERE post_type_id = 1 AND year = 2009\n",
    "            GROUP BY year, myCol1) as exploded\n",
    "    WHERE exploded.year = 2009) AS p\n",
    "ON c.token = p.token\n",
    "ORDER BY c.rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "OK\n",
      "Time taken: 0.308 seconds\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar]\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar]\n",
      "Query ID = jovyan_20180809235555_369ddc8e-2fd6-4d1f-93e8-0d93e46637b6\n",
      "Total jobs = 8\n",
      "Launching Job 1 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1533854501399_0018, Tracking URL = http://dab5de7b4ed2:8088/proxy/application_1533854501399_0018/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1533854501399_0018\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2018-08-09 23:55:13,640 Stage-1 map = 0%,  reduce = 0%\n",
      "2018-08-09 23:55:17,753 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.05 sec\n",
      "2018-08-09 23:55:21,838 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 3.46 sec\n",
      "MapReduce Total cumulative CPU time: 3 seconds 460 msec\n",
      "Ended Job = job_1533854501399_0018\n",
      "Launching Job 2 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1533854501399_0019, Tracking URL = http://dab5de7b4ed2:8088/proxy/application_1533854501399_0019/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1533854501399_0019\n",
      "Hadoop job information for Stage-6: number of mappers: 1; number of reducers: 1\n",
      "2018-08-09 23:55:33,158 Stage-6 map = 0%,  reduce = 0%\n",
      "2018-08-09 23:55:37,247 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 1.56 sec\n",
      "2018-08-09 23:55:42,348 Stage-6 map = 100%,  reduce = 100%, Cumulative CPU 2.95 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 950 msec\n",
      "Ended Job = job_1533854501399_0019\n",
      "Launching Job 3 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1533854501399_0020, Tracking URL = http://dab5de7b4ed2:8088/proxy/application_1533854501399_0020/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1533854501399_0020\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2018-08-09 23:55:52,900 Stage-2 map = 0%,  reduce = 0%\n",
      "2018-08-09 23:55:57,009 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 0.99 sec\n",
      "2018-08-09 23:56:01,124 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.58 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 580 msec\n",
      "Ended Job = job_1533854501399_0020\n",
      "Launching Job 4 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1533854501399_0021, Tracking URL = http://dab5de7b4ed2:8088/proxy/application_1533854501399_0021/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1533854501399_0021\n",
      "Hadoop job information for Stage-7: number of mappers: 1; number of reducers: 1\n",
      "2018-08-09 23:56:11,401 Stage-7 map = 0%,  reduce = 0%\n",
      "2018-08-09 23:56:15,504 Stage-7 map = 100%,  reduce = 0%, Cumulative CPU 0.81 sec\n",
      "2018-08-09 23:56:19,586 Stage-7 map = 100%,  reduce = 100%, Cumulative CPU 2.42 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 420 msec\n",
      "Ended Job = job_1533854501399_0021\n",
      "Launching Job 5 out of 8\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1533854501399_0022, Tracking URL = http://dab5de7b4ed2:8088/proxy/application_1533854501399_0022/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1533854501399_0022\n",
      "Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "2018-08-09 23:56:30,505 Stage-3 map = 0%,  reduce = 0%\n",
      "2018-08-09 23:56:34,585 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 0.64 sec\n",
      "2018-08-09 23:56:38,686 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 1.52 sec\n",
      "MapReduce Total cumulative CPU time: 1 seconds 520 msec\n",
      "Ended Job = job_1533854501399_0022\n",
      "Stage-10 is selected by condition resolver.\n",
      "Stage-4 is filtered out by condition resolver.\n",
      "Execution log at: /tmp/jovyan/jovyan_20180809235555_369ddc8e-2fd6-4d1f-93e8-0d93e46637b6.log\n",
      "2018-08-09 11:56:41\tStarting to launch local task to process map join;\tmaximum memory = 477626368\n",
      "2018-08-09 11:56:41\tDump the side-table for tag: 1 with group count: 2369 into file: file:/tmp/jovyan/938fb9da-11e5-4afa-914f-0dfac825f302/hive_2018-08-09_23-55-06_281_6630274859936629747-1/-local-10009/HashTable-Stage-8/MapJoin-mapfile01--.hashtable\n",
      "2018-08-09 11:56:42\tUploaded 1 File to: file:/tmp/jovyan/938fb9da-11e5-4afa-914f-0dfac825f302/hive_2018-08-09_23-55-06_281_6630274859936629747-1/-local-10009/HashTable-Stage-8/MapJoin-mapfile01--.hashtable (76823 bytes)\n",
      "2018-08-09 11:56:42\tEnd of local task; Time Taken: 0.466 sec.\n",
      "Execution completed successfully\n",
      "MapredLocal task succeeded\n",
      "Launching Job 7 out of 8\n",
      "Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "Starting Job = job_1533854501399_0023, Tracking URL = http://dab5de7b4ed2:8088/proxy/application_1533854501399_0023/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1533854501399_0023\n",
      "Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 0\n",
      "2018-08-09 23:56:48,424 Stage-8 map = 0%,  reduce = 0%\n",
      "2018-08-09 23:56:52,497 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 0.84 sec\n",
      "MapReduce Total cumulative CPU time: 840 msec\n",
      "Ended Job = job_1533854501399_0023\n",
      "Launching Job 8 out of 8\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1533854501399_0024, Tracking URL = http://dab5de7b4ed2:8088/proxy/application_1533854501399_0024/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1533854501399_0024\n",
      "Hadoop job information for Stage-5: number of mappers: 1; number of reducers: 1\n",
      "2018-08-09 23:57:03,130 Stage-5 map = 0%,  reduce = 0%\n",
      "2018-08-09 23:57:07,207 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 0.68 sec\n",
      "2018-08-09 23:57:11,282 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 1.72 sec\n",
      "MapReduce Total cumulative CPU time: 1 seconds 720 msec\n",
      "Ended Job = job_1533854501399_0024\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 3.46 sec   HDFS Read: 835510 HDFS Write: 283234 SUCCESS\n",
      "Stage-Stage-6: Map: 1  Reduce: 1   Cumulative CPU: 2.95 sec   HDFS Read: 145612 HDFS Write: 67863 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 2.58 sec   HDFS Read: 289216 HDFS Write: 364 SUCCESS\n",
      "Stage-Stage-7: Map: 1  Reduce: 1   Cumulative CPU: 2.42 sec   HDFS Read: 73723 HDFS Write: 74637 SUCCESS\n",
      "Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 1.52 sec   HDFS Read: 4477 HDFS Write: 364 SUCCESS\n",
      "Stage-Stage-8: Map: 1   Cumulative CPU: 0.84 sec   HDFS Read: 4867 HDFS Write: 391 SUCCESS\n",
      "Stage-Stage-5: Map: 1  Reduce: 1   Cumulative CPU: 1.72 sec   HDFS Read: 5437 HDFS Write: 188 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 15 seconds 490 msec\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javascript\t1\t5\t2771\t192\n",
      "java\t2\t2\t2033\t243\n",
      "android\t3\t52\t1809\t25\n",
      "php\t4\t3\t1673\t215\n",
      "python\t5\t11\t1585\t108\n",
      "c#\t6\t1\t1519\t423\n",
      "html\t7\t14\t1212\t84\n",
      "jquery\t8\t8\t1167\t141\n",
      "ios\t9\t186\t914\t7\n",
      "css\t10\t20\t801\t59\n",
      "Time taken: 127.208 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! hive -f query2.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative solution (Improved readability - by Maxim Uvarov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query.hql\n",
    "\n",
    "USE stackoverflow_;\n",
    "\n",
    "\n",
    "WITH questions AS (\n",
    "    SELECT year, tags_expl, COUNT(*) AS cnt\n",
    "    FROM posts\n",
    "    LATERAL VIEW explode(tags) tagsTable AS tags_expl\n",
    "    WHERE post_type_id = 1 AND year IN (2009, 2016)\n",
    "    GROUP BY year, tags_expl\n",
    ")\n",
    "SELECT concat_ws(\"\\t\", tags_expl, string(rank_2016), string(rank_2009), string(cnt_2016), string(cnt_2009))\n",
    "FROM (\n",
    "    SELECT\n",
    "        t_2016.tags_expl AS tags_expl\n",
    "        ,t_2016.rank AS rank_2016\n",
    "        ,t_2009.rank AS rank_2009\n",
    "        ,t_2016.cnt AS cnt_2016\n",
    "        ,t_2009.cnt AS cnt_2009\n",
    "    FROM (\n",
    "        SELECT tags_expl, cnt, RANK() OVER (ORDER BY cnt DESC) rank\n",
    "        FROM questions\n",
    "        WHERE year = 2016\n",
    "        LIMIT 10\n",
    "    ) t_2016\n",
    "    LEFT OUTER JOIN (\n",
    "        SELECT tags_expl, cnt, RANK() OVER (ORDER BY cnt DESC) rank\n",
    "        FROM questions\n",
    "        WHERE year = 2009\n",
    "    ) t_2009\n",
    "    ON t_2016.tags_expl = t_2009.tags_expl\n",
    "    ORDER BY rank_2016\n",
    ") t_top;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
