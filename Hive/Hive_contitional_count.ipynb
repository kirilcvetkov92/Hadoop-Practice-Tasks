{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have precreated database `stackoverflow_`. Firstly, investigate it. What tables does it has?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive Assignment 3. DML: Calculate Amount of Posts per User Age\n",
    "Use Hive to complete the following task. Input tables was described in Hive Task1 and Hive Task2.\n",
    "\n",
    "Calculate number of questions and answers depending on users' age. Use Ð°ge from 'users' table, filter out users if their age is undefined. Output format:\n",
    "\n",
    "\n",
    "`age <tab> number of questions <tab> number of answers`\n",
    "\n",
    "Example:\n",
    "\n",
    "`22 12345 5678`\n",
    "Output all ages. Order by age, increment.\n",
    "\n",
    "The part of the result on the sample dataset:\n",
    "\n",
    "`...\n",
    "21  11  24\n",
    "22  6   18\n",
    "23  12  15\n",
    "24  16  27\n",
    "25  20  33\n",
    "...\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "OK\n",
      "Time taken: 0.314 seconds\n",
      "OK\n",
      "posts\n",
      "users\n",
      "Time taken: 0.118 seconds, Fetched: 2 row(s)\n"
     ]
    }
   ],
   "source": [
    "! hive --database stackoverflow_ -e 'show tables'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Querying to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add necessary JAR-files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query.hql\n",
    "\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include precreated database `stackoverflow_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a query.hql\n",
    "\n",
    "USE stackoverflow_;\n",
    "DESCRIBE posts;\n",
    "DESCRIBE users;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, write a simple query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a query.hql\n",
    "\n",
    "SELECT * FROM posts LIMIT 10;\n",
    "SELECT * FROM users LIMIT 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's execute received `HiveQL`-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar]\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar]\n",
      "OK\n",
      "Time taken: 0.311 seconds\n",
      "OK\n",
      "id                  \tint                 \t                    \n",
      "post_type_id        \ttinyint             \t                    \n",
      "date                \tstring              \t                    \n",
      "owner_user_id       \tint                 \t                    \n",
      "parent_id           \tint                 \t                    \n",
      "score               \tint                 \t                    \n",
      "favorite_count      \tint                 \t                    \n",
      "tags                \tarray<string>       \t                    \n",
      "year                \tstring              \t                    \n",
      "month               \tstring              \t                    \n",
      "\t \t \n",
      "# Partition Information\t \t \n",
      "# col_name            \tdata_type           \tcomment             \n",
      "\t \t \n",
      "year                \tstring              \t                    \n",
      "month               \tstring              \t                    \n",
      "Time taken: 0.323 seconds, Fetched: 16 row(s)\n",
      "OK\n",
      "id                  \tint                 \t                    \n",
      "reputation          \tint                 \t                    \n",
      "creation_date       \tstring              \t                    \n",
      "display_name        \tstring              \t                    \n",
      "location            \tstring              \t                    \n",
      "views               \tint                 \t                    \n",
      "up_votes            \tint                 \t                    \n",
      "down_votes          \tint                 \t                    \n",
      "age                 \tint                 \t                    \n",
      "account_id          \tint                 \t                    \n",
      "Time taken: 0.038 seconds, Fetched: 10 row(s)\n",
      "OK\n",
      "45\t2\t2008-08-01T12:56:37.920\t39\t39\t34\tNULL\tNULL\t2008\t2008-08\n",
      "243\t2\t2008-08-01T22:31:36.137\t71\t234\t12\tNULL\tNULL\t2008\t2008-08\n",
      "304\t2\t2008-08-02T01:38:14.077\t91\t109\t2\tNULL\tNULL\t2008\t2008-08\n",
      "629\t2\t2008-08-03T07:28:54.070\t122\t626\t38\tNULL\tNULL\t2008\t2008-08\n",
      "893\t2\t2008-08-03T23:38:05.113\t234\t871\t6\tNULL\tNULL\t2008\t2008-08\n",
      "1394\t2\t2008-08-04T16:38:03.667\t91\t1390\t16\tNULL\tNULL\t2008\t2008-08\n",
      "1686\t2\t2008-08-04T23:08:18.603\t316\t1669\t43\tNULL\tNULL\t2008\t2008-08\n",
      "2069\t2\t2008-08-05T10:22:55.653\t307\t2056\t23\tNULL\tNULL\t2008\t2008-08\n",
      "2712\t2\t2008-08-05T19:09:08.213\t350\t2639\t10\tNULL\tNULL\t2008\t2008-08\n",
      "2799\t2\t2008-08-05T20:26:08.103\t308\t2767\t34\tNULL\tNULL\t2008\t2008-08\n",
      "Time taken: 0.382 seconds, Fetched: 10 row(s)\n",
      "OK\n",
      "37\t4146\t2008-08-01T12:44:00.723\tWally Lawless\tGeorgetown, Canada\t654\t256\t18\t35\t28\n",
      "169\t4825\t2008-08-02T22:51:03.507\tArnold Zokas\tLondon, United Kingdom\t585\t1956\t14\tNULL\t138\n",
      "194\t15481\t2008-08-03T10:56:49.987\tAdam Haile\tUnited States\t1973\t217\t18\t33\t157\n",
      "338\t37578\t2008-08-04T18:34:44.117\tFrank Krueger\tUnited States\t3941\t2411\t93\t36\t272\n",
      "480\t276\t2008-08-06T08:40:05.797\tmdy\tAsia\t79\t49\t0\t28\t381\n",
      "756\t2358\t2008-08-08T15:31:50.013\tSimon Gillbee\tPearland, TX\t478\t352\t25\t45\t587\n",
      "923\t58\t2008-08-10T14:25:39.540\tAnotherHowie\tUnited Kingdom\t32\t2\t0\t45\t706\n",
      "1097\t8036\t2008-08-12T11:40:09.933\tGeoff\tStow, OH\t527\t473\t30\t46\t838\n",
      "1462\t2011\t2008-08-15T17:26:18.470\tcrono\tGermany\t119\t73\t1\t35\t1101\n",
      "1539\t2476\t2008-08-16T13:31:36.823\tRyan P\tUnited States\t233\t72\t9\t33\t1158\n",
      "Time taken: 0.164 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "! hive -f query.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting query2.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query2.hql\n",
    "USE stackoverflow_;\n",
    "\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar;\n",
    "\n",
    "Select u.age,        \n",
    "       COUNT(CASE WHEN p.post_type_id=1 THEN u.id ELSE NULL END) AS qc,\n",
    "       COUNT(CASE WHEN p.post_type_id=2 THEN u.id ELSE NULL END) AS ac\n",
    "FROM\n",
    "    (SELECT id, age FROM \n",
    "    users \n",
    "    WHERE age is not null) AS u\n",
    "JOIN\n",
    "    (Select owner_user_id, post_type_id FROM\n",
    "     posts\n",
    "     WHERE post_type_id in (1,2)) p\n",
    "ON u.id = p.owner_user_id\n",
    "GROUP BY u.age\n",
    "ORDER BY u.age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "OK\n",
      "Time taken: 0.318 seconds\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar]\n",
      "Added [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar] to class path\n",
      "Added resources: [/opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar]\n",
      "Query ID = jovyan_20180810013333_9d76e9e1-3ca3-42cb-aeba-db992eb5e65a\n",
      "Total jobs = 2\n",
      "Execution log at: /tmp/jovyan/jovyan_20180810013333_9d76e9e1-3ca3-42cb-aeba-db992eb5e65a.log\n",
      "2018-08-10 01:33:50\tStarting to launch local task to process map join;\tmaximum memory = 477626368\n",
      "2018-08-10 01:33:51\tDump the side-table for tag: 0 with group count: 5951 into file: file:/tmp/jovyan/6ae657cc-8ac4-402c-acfe-23482d9c0cde/hive_2018-08-10_01-33-47_949_3687207331990889256-1/-local-10005/HashTable-Stage-2/MapJoin-mapfile00--.hashtable\n",
      "2018-08-10 01:33:51\tUploaded 1 File to: file:/tmp/jovyan/6ae657cc-8ac4-402c-acfe-23482d9c0cde/hive_2018-08-10_01-33-47_949_3687207331990889256-1/-local-10005/HashTable-Stage-2/MapJoin-mapfile00--.hashtable (137665 bytes)\n",
      "2018-08-10 01:33:51\tEnd of local task; Time Taken: 0.582 sec.\n",
      "Execution completed successfully\n",
      "MapredLocal task succeeded\n",
      "Launching Job 1 out of 2\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1533854501399_0033, Tracking URL = http://dab5de7b4ed2:8088/proxy/application_1533854501399_0033/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1533854501399_0033\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2018-08-10 01:33:58,313 Stage-2 map = 0%,  reduce = 0%\n",
      "2018-08-10 01:34:02,429 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 2.79 sec\n",
      "2018-08-10 01:34:06,534 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 2.79 sec\n",
      "MapReduce Total cumulative CPU time: 2 seconds 790 msec\n",
      "Ended Job = job_1533854501399_0033\n",
      "Launching Job 2 out of 2\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1533854501399_0034, Tracking URL = http://dab5de7b4ed2:8088/proxy/application_1533854501399_0034/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1533854501399_0034\n",
      "Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "2018-08-10 01:34:18,276 Stage-3 map = 0%,  reduce = 0%\n",
      "2018-08-10 01:34:21,336 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 0.65 sec\n",
      "2018-08-10 01:34:25,433 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 1.58 sec\n",
      "MapReduce Total cumulative CPU time: 1 seconds 580 msec\n",
      "Ended Job = job_1533854501399_0034\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.0 sec   HDFS Read: 2261251 HDFS Write: 1056 SUCCESS\n",
      "Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 1.58 sec   HDFS Read: 5619 HDFS Write: 376 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 5 seconds 580 msec\n",
      "OK\n",
      "14\t1\t0\n",
      "15\t1\t2\n",
      "16\t2\t0\n",
      "17\t0\t1\n",
      "18\t4\t1\n",
      "19\t1\t1\n",
      "20\t0\t2\n",
      "21\t11\t24\n",
      "22\t6\t18\n",
      "23\t12\t15\n",
      "24\t16\t27\n",
      "25\t20\t33\n",
      "26\t23\t44\n",
      "27\t28\t56\n",
      "28\t24\t37\n",
      "29\t24\t66\n",
      "30\t26\t67\n",
      "31\t17\t33\n",
      "32\t13\t48\n",
      "33\t11\t40\n",
      "34\t24\t36\n",
      "35\t12\t42\n",
      "36\t8\t64\n",
      "37\t9\t35\n",
      "38\t6\t17\n",
      "39\t3\t7\n",
      "40\t1\t13\n",
      "41\t5\t20\n",
      "42\t5\t22\n",
      "43\t2\t26\n",
      "44\t7\t35\n",
      "45\t1\t4\n",
      "46\t7\t9\n",
      "47\t1\t1\n",
      "48\t1\t1\n",
      "49\t1\t26\n",
      "50\t1\t26\n",
      "51\t4\t5\n",
      "52\t0\t2\n",
      "53\t0\t2\n",
      "54\t0\t1\n",
      "57\t0\t3\n",
      "58\t1\t57\n",
      "60\t0\t6\n",
      "61\t0\t3\n",
      "64\t2\t1\n",
      "86\t0\t1\n",
      "96\t3\t1\n",
      "Time taken: 39.677 seconds, Fetched: 48 row(s)\n"
     ]
    }
   ],
   "source": [
    "! hive -f query2.hql"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
