{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GfW2gwDt8Grj"
   },
   "source": [
    "## Task 1. Stateful wordcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1glnG-f8Grk"
   },
   "source": [
    "In this task you're receiving batches in real time through DStream. You need to create the Wordcount program with saving and updating the state after each batch. \n",
    "\n",
    "You have to print the TOP-10 most popular words in the input dataset and its quantity. \n",
    "\n",
    "There are several points for this task:\n",
    "\n",
    "1) You have to print data only at the end. The criteria is if you have received first empty rdd, the stream is finished. At this moment you have to print the result and stop the context.\n",
    "\n",
    "2) You may split the line with using $flatMap$ method in Dstream.\n",
    "\n",
    "3) In this task you need to filter out short words (with length less or equal than 3). For this aim you may use $filter$ method in Dstream.\n",
    "\n",
    "4) Remember that you should use string lowercase. You may use $map$ method in Dstream to transform words to such case.\n",
    "\n",
    "5) You may use  $reduceByKey$ in Dstream to merge the tuples with the same key by summing the word count value.\n",
    "\n",
    "6) In this task, you need to be able to maintain the state across the batches. You may use the $updateStateByKey()$ method, which provides access to the state variable and help you to implement \"stateful\" approach. You can update the current state with results of every batch.\n",
    "\n",
    "You may find more useful methods in the following sources:\n",
    "\n",
    "$\\cdot \\quad$ Book \"Learning Spark: Lightning-Fast Big Data Analysis\" by Holden Karau.\n",
    "\n",
    "$\\cdot \\quad \\href{https://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark-streaming-module}{ SparkStreaming \\ documentation}$\n",
    "\n",
    "Here you can find the starter for the main steps of the task. You can use other methods to get the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQADoZxB8Grk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head -20 /data/wiki/en_articles_streaming/articles-part_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1FqHOOD0kRJ3"
   },
   "source": [
    "**NB.** Please don't change the cell below. It is used for emulation realtime batch arriving. But figure out the code, it will help you when you'll work with real SparkStreaming applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VfGtE-J_8Grm"
   },
   "outputs": [],
   "source": [
    "# Preparing SparkContext\n",
    "sc = SparkContext(master='local[4]')\n",
    "\n",
    "# Preparing base RDD with the input data\n",
    "DATA_PATH = \"/data/wiki/en_articles_streaming\"\n",
    "\n",
    "batches = [sc.textFile(os.path.join(DATA_PATH, path)) for path in os.listdir(DATA_PATH)]\n",
    "\n",
    "# Creating Dstream to emulate realtime data generating\n",
    "BATCH_TIMEOUT = 5  # Timeout between batch generation\n",
    "ssc = StreamingContext(sc, BATCH_TIMEOUT)\n",
    "dstream = ssc.queueStream(rdds=batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yw_69uKz8Gro"
   },
   "outputs": [],
   "source": [
    "finished = False\n",
    "printed = False\n",
    "\n",
    "\n",
    "def set_ending_flag(rdd):\n",
    "    global finished\n",
    "    if rdd.isEmpty():\n",
    "        finished = True\n",
    "\n",
    "\n",
    "def print_only_at_the_end(rdd):\n",
    "    global printed\n",
    "    \n",
    "    rdd.count()\n",
    "    #Transformations are executing lazy, immutable and produces new rdd during executing Directed acyclic graph flow, once action is provided \n",
    "    #So the transformation is not executed till we get some action\n",
    "    #So the transformation is not executed till we get some action, so In my case, no transformation won't be executed till it pass the if case, and once it pass the if, there is an action called *.collect()*\n",
    "    #Inside the transformations in the dag we still count the dstream transformations, because they are actually in the RDD\n",
    "    if finished and not printed:\n",
    "\n",
    "        ans = rdd.sortBy(lambda x : x[1], ascending=False).collect()\n",
    "   \n",
    "        for key in ans[:10]:\n",
    "            print(key[0], \"\\t\", key[1])\n",
    "             \n",
    "        printed = True\n",
    "\n",
    "# If we have received an empty rdd, the stream is finished.\n",
    "# So print the result and stop the context.\n",
    "dstream.foreachRDD(set_ending_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregator(values, old):\n",
    "    return (old or 0) + sum(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parse_article(line):\n",
    "    try:\n",
    "        article_id, text = line.rstrip().lower().split('\\t', 1)\n",
    "        text = re.sub(\"^\\W+|\\W+$\", \"\", text, flags=re.UNICODE)\n",
    "        words = re.split(\"\\W*\\s+\\W*\", text, flags=re.UNICODE)\n",
    "        return words\n",
    "    except ValueError as e:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line = \"12\tAnarchism         Anarchism is often defined as a political philosophy which holds the state to be undesirable, unnecessary, or harmful.          The following sources cite anarchism as a political philosophy:      Slevin, Carl. \\\"Anarchism.\\\"\"\n",
    "\n",
    "# print(parse_article(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "81GjQtpA8Grp"
   },
   "outputs": [],
   "source": [
    "# Type your code for data processing and aggregation here\n",
    "\n",
    "dstream.flatMap(lambda line: parse_article(line))\\\n",
    "    .filter(lambda word : len(word)>=4)\\\n",
    "    .map(lambda word: (word.lower(), 1))\\\n",
    "    .reduceByKey(lambda a,b : a+b)\\\n",
    "    .updateStateByKey(aggregator)\\\n",
    "    .foreachRDD(print_only_at_the_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_msKdjZ-pv0A"
   },
   "source": [
    "**NB.** Please don't change the cell below. It is used for stopping SparkStreaming context and Spark context when the stream finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9pgh8R88Grq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that \t 81572\n",
      "with \t 79559\n",
      "from \t 58201\n",
      "which \t 42198\n",
      "this \t 38252\n",
      "were \t 34403\n",
      "also \t 31574\n",
      "have \t 29871\n",
      "their \t 24579\n",
      "other \t 23538\n"
     ]
    }
   ],
   "source": [
    "ssc.checkpoint('./checkpoint')  # checkpoint for storing current state        \n",
    "ssc.start()\n",
    "while not printed:\n",
    "    pass\n",
    "ssc.stop()  # when the result printed, stop the SparkStreaming context\n",
    "sc.stop()  # stop the Spark context to be able restart the code without restarting the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XbICM7b9s4wF"
   },
   "source": [
    "Here you can see the part of an output on the sample dataset:\n",
    "\n",
    "```\n",
    "...\n",
    "which 42198\n",
    "this 38252\n",
    "were 34403\n",
    "...\n",
    "```\n",
    "\n",
    "Of course, the numbers may be different but not very much (the error about 1% will be accepted)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "UserFlavorTask1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
